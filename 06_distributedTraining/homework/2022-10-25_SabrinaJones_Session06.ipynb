{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8359834",
   "metadata": {},
   "source": [
    "# Scaling MNIST example\n",
    "Please put your homework in this folder. This includes\n",
    "1. tensorflow2_mnist_hvd.py code\n",
    "2. accuracy plots for 1, 2, 4, 8, 16 GPU runs. \n",
    "\n",
    "And provide the link to your ./homework folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3df3257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "WARNING: There was an error initializing an OpenFabrics device.\n",
      "\n",
      "  Local host:   thetagpu06\n",
      "  Local device: mlx5_0\n",
      "--------------------------------------------------------------------------\n",
      "usage: ipykernel_launcher.py [-h] -c CONFIG_FILENAME [-l LOGDIR] [-n NSTEPS]\n",
      "                             [--interop INTEROP] [--intraop INTRAOP]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -c/--config\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lus/theta-fs0/software/thetagpu/conda/2022-07-01/mconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os,glob\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.profiler import trace\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import horovod.tensorflow as hvd\n",
    "hvd.init()\n",
    "\n",
    "# these are initialized in the get_datasets function and used later\n",
    "labels_hash = None\n",
    "crop_size = None\n",
    "\n",
    "\n",
    "@trace.trace_wrapper('get_datasets')\n",
    "def get_datasets(config):\n",
    "   # these global variables will be initizlized\n",
    "   global labels_hash,crop_size\n",
    "\n",
    "   # set the crop size of the output images, e.g. [256,256]\n",
    "   crop_size = tf.constant(config['data']['crop_image_size'])\n",
    "   # these are paths to text files containing a list, one entry per line,\n",
    "   # of all the training JPEGs and testing JPEGs\n",
    "   # it's assumed the full path to the JPEGs is like this:\n",
    "   # /.../ILSVRC/Data/CLS-LOC/train/n02437312/n02437312_8688.JPEG\n",
    "   # because the class label comes from the last folder text.\n",
    "   train_filelist = config['data']['train_filelist']\n",
    "   test_filelist = config['data']['test_filelist']\n",
    "\n",
    "   assert os.path.exists(train_filelist)\n",
    "   assert os.path.exists(test_filelist)\n",
    "\n",
    "   # this function uses that class label from the filename path\n",
    "   # and builds a map from the string labels like the above \"n02537312\"\n",
    "   # to a unique integer value 0-999. This is more suitable for\n",
    "   # network classifciation than a string.\n",
    "   labels_hash = get_label_tables(config, train_filelist)\n",
    "\n",
    "   # this function creates the tf.dataset.Dataset objects for each list\n",
    "   # of input JPEGs.\n",
    "   train_ds = build_dataset_from_filelist(config,train_filelist)\n",
    "   valid_ds = build_dataset_from_filelist(config,test_filelist)\n",
    "\n",
    "   return train_ds,valid_ds\n",
    "\n",
    "\n",
    "## Create a hash table for labels from string to int \n",
    "@trace.trace_wrapper('get_label_tables')\n",
    "def get_label_tables(config, train_filelist):\n",
    "\n",
    "   # get the first filename\n",
    "   with open(train_filelist) as file:\n",
    "      filepath = file.readline().strip()\n",
    "\n",
    "   # parse the filename to extract the \"n02537312\" string\n",
    "   # from the full path which is assumed to be similar to this\n",
    "   # /.../ILSVRC/Data/CLS-LOC/train/n02437312/n02437312_8688.JPEG\n",
    "   # and convert that string to a unique value from 0-999\n",
    "\n",
    "   # this extracts the path up to: /.../ILSVRC/Data/CLS-LOC/train/\n",
    "   label_path = '/'.join(filepath.split('/')[:-2])\n",
    "   # this globs for all the directories like \"n02537312\" to get \n",
    "   # list of the string labels\n",
    "   labels = glob.glob(label_path + os.path.sep + '*')\n",
    "   if config['hvd'].rank() == 0:\n",
    "      print(f'num labels: {len(labels)}')\n",
    "   # this removes the leading path from the label directories\n",
    "   labels = [os.path.basename(i) for i in labels]\n",
    "   # create a list of integers as long as the number of labels\n",
    "   hash_values = tf.range(len(labels))\n",
    "   # convert python list of strings to a tensorflow vector\n",
    "   hash_keys = tf.constant(labels, dtype=tf.string)\n",
    "   # build a key-value lookup using Tensorflow tools\n",
    "   labels_hash_init = tf.lookup.KeyValueTensorInitializer(hash_keys, hash_values)\n",
    "   # build a lookup table based on those key-value pairs (returns -1 for undefined keys)\n",
    "   labels_hash = tf.lookup.StaticHashTable(labels_hash_init, -1)\n",
    "\n",
    "   return labels_hash\n",
    "\n",
    "\n",
    "# take a config dictionary and a path to a filelist\n",
    "# return a tf.dataset.Dataset object that will iterate over the JPEGs in filelist\n",
    "@trace.trace_wrapper('build_dataset_from_filelist')\n",
    "def build_dataset_from_filelist(config,filelist_filename):\n",
    "   if config['hvd'].rank() == 0:\n",
    "      print(f'build dataset {filelist_filename}')\n",
    "\n",
    "   dc = config['data']\n",
    "\n",
    "   # if running horovod(MPI) need to shard the dataset based on rank\n",
    "   numranks = 1\n",
    "   if config['hvd']:\n",
    "      numranks = config['hvd'].size()\n",
    "\n",
    "   # loading full filelist\n",
    "   filelist = []\n",
    "   with open(filelist_filename) as file:\n",
    "      for line in file:\n",
    "         filelist.append(line.strip())\n",
    "\n",
    "   # provide user with estimated batches in epoch\n",
    "   batches_per_rank = int(len(filelist) / dc['batch_size'] / numranks)\n",
    "   if config['hvd'].rank() == 0:\n",
    "      print(f'input filelist contains {len(filelist)} files, estimated batches per rank {batches_per_rank}')\n",
    "   \n",
    "   # convert python list to tensorflow vector object\n",
    "   filelist = tf.data.Dataset.from_tensor_slices(filelist)\n",
    "\n",
    "   # if using horovod (MPI) shard the data based on total ranks (size) and rank\n",
    "   if config['hvd']:\n",
    "      filelist = filelist.shard(config['hvd'].size(), config['hvd'].rank())\n",
    "   \n",
    "   # shuffle the data, set shuffle buffer (needs to be large), and reshuffle after each epoch\n",
    "   filelist = filelist.shuffle(dc['shuffle_buffer'],reshuffle_each_iteration=dc['reshuffle_each_iteration'])\n",
    "\n",
    "   # run 'load_image_label_bb' on each input image file, process multiple files in parallel\n",
    "   # this function opens the JPEG, converts it to a tensorflow vector and gets the truth class label\n",
    "   ds = filelist.map(load_image_label_bb,\n",
    "                     num_parallel_calls=config['data']['num_parallel_readers'])\n",
    "                     \n",
    "   # unbatch called because some JPEGs result in more than 1 image returned\n",
    "   ds = ds.apply(tf.data.Dataset.unbatch)\n",
    "\n",
    "   # batch the data\n",
    "   ds = ds.batch(dc['batch_size'])\n",
    "\n",
    "   # setup a pipeline that pre-fetches images before they are needed (keeps CPU busy)\n",
    "   ds = ds.prefetch(buffer_size=config['data']['prefetch_buffer_size'])  \n",
    "\n",
    "   return ds\n",
    "\n",
    "\n",
    "# this function parses the image path, uses the label hash to convert the string\n",
    "# label in the path to a numerical label, decodes the input JPEG, and returns\n",
    "# the input image and label\n",
    "@trace.trace_wrapper('load_image_label_bb')\n",
    "def load_image_label_bb(image_path):\n",
    "\n",
    "   # for each JPEG, there is an Annotation file that contains a list of\n",
    "   # classes contained in the image and a bounding box for each object.\n",
    "   # However, some images contain a single class, in which case the\n",
    "   # dataset contains no annotation file which is annoying, but...\n",
    "   # Images with multiple objects per file are always the same class.\n",
    "   label = tf.strings.split(image_path, os.path.sep)[-2]\n",
    "   annot_path = tf.strings.regex_replace(image_path,'Data','Annotations')\n",
    "   annot_path = tf.strings.regex_replace(annot_path,'JPEG','xml')\n",
    "\n",
    "   # open the annotation file and retrieve the bounding boxes and indices\n",
    "   bounding_boxes,box_indices = tf.py_function(get_bounding_boxes,[annot_path],[tf.float32,tf.int32])\n",
    "\n",
    "   # open the JPEG\n",
    "   img = tf.io.read_file(image_path)\n",
    "   # convert the compressed string to a 3D uint8 tensor\n",
    "   img = tf.image.decode_jpeg(img, channels=3)\n",
    "   # add batching index [batch,width,height,channel]\n",
    "   img = tf.expand_dims(img,0)\n",
    "\n",
    "   # create individual images based on bounding boxes\n",
    "   imgs = tf.image.crop_and_resize(img,bounding_boxes,box_indices,crop_size)\n",
    "\n",
    "   # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "   imgs = tf.image.convert_image_dtype(imgs, tf.float16)\n",
    "   # resize the image to the desired size. networks don't like variable sized arrays.\n",
    "   imgs = tf.image.resize(imgs, crop_size)\n",
    "   # convert string label to numerical label\n",
    "   label = labels_hash.lookup(label)\n",
    "   # duplicate labels to match the number of images created from bounding boxes\n",
    "   labels = tf.fill([tf.shape(imgs)[0]],label)\n",
    "   # return images and labels\n",
    "   return imgs, labels\n",
    "\n",
    "\n",
    "# this function opens the annotation XML file and parses the contents\n",
    "# the contents include a list of objects in the JPEG, a label and\n",
    "# bounding box for each object\n",
    "@trace.trace_wrapper('get_bounding_boxes')\n",
    "def get_bounding_boxes(filename):\n",
    "   filename = bytes.decode(filename.numpy())\n",
    "   try:\n",
    "      with tf.profiler.experimental.Trace('read_xml'):\n",
    "         tree = ET.parse(filename)\n",
    "         root = tree.getroot()\n",
    "\n",
    "      img_size = root.find('size')\n",
    "      img_width = int(img_size.find('width').text)\n",
    "      img_height = int(img_size.find('height').text)\n",
    "      # img_depth = int(img_size.find('depth').text)\n",
    "\n",
    "      objs = root.findall('object')\n",
    "      bndbxs = []\n",
    "      # label = None\n",
    "      for object in objs:\n",
    "         # label = object.find('name').text\n",
    "         bndbox = object.find('bndbox')\n",
    "         bndbxs.append([\n",
    "            float(bndbox.find('ymin').text) / (img_height - 1),\n",
    "            float(bndbox.find('xmin').text) / (img_width - 1),\n",
    "            float(bndbox.find('ymax').text) / (img_height - 1),\n",
    "            float(bndbox.find('xmax').text) / (img_width - 1)\n",
    "         ])\n",
    "   except FileNotFoundError:\n",
    "      bndbxs = [[0,0,1,1]]\n",
    "\n",
    "   return np.asarray(bndbxs,float),np.zeros(len(bndbxs))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   # parse command line\n",
    "   import argparse,json,time\n",
    "   parser = argparse.ArgumentParser(description='test this')\n",
    "   parser.add_argument('-c', '--config', dest='config_filename',\n",
    "                       help='configuration filename in json format',\n",
    "                       required=True)\n",
    "   parser.add_argument('-l','--logdir', dest='logdir',\n",
    "                       help='log output directory',default='logdir')\n",
    "   parser.add_argument('-n','--nsteps', dest='nsteps',\n",
    "                       help='number of steps to run',default=10,type=int)\n",
    "   parser.add_argument('--interop',type=int,help='set Tensorflow \"inter_op_parallelism_threads\" session config varaible ',default=None)\n",
    "   parser.add_argument('--intraop',type=int,help='set Tensorflow \"intra_op_parallelism_threads\" session config varaible ',default=None)\n",
    "\n",
    "   args = parser.parse_args()\n",
    "\n",
    "   gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "   for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "   if gpus:\n",
    "      tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    "\n",
    "   print(\"GPUs Available: %s\" % tf.config.get_visible_devices('GPU'))\n",
    "\n",
    "   # parse config file\n",
    "   config = json.load(open(args.config_filename))\n",
    "   config['hvd'] = hvd\n",
    "   \n",
    "   # define some parallel processing sizes\n",
    "   if args.interop is not None:\n",
    "      tf.config.threading.set_inter_op_parallelism_threads(args.interop)\n",
    "   if args.intraop is not None:\n",
    "      tf.config.threading.set_intra_op_parallelism_threads(args.intraop)\n",
    "   \n",
    "   # use the tensorflow profiler here\n",
    "   if hvd.rank() == 0:\n",
    "      tf.profiler.experimental.start(args.logdir)\n",
    "   # call function to build dataset objects\n",
    "   # both of the returned objects are tf.dataset.Dataset objects\n",
    "   trainds, testds = get_datasets(config)\n",
    "   # can iterate over a dataset object\n",
    "   trainds = iter(trainds)\n",
    "   start = time.time()\n",
    "   for i in range(args.nsteps):\n",
    "      # profile data pipeline\n",
    "      with tf.profiler.experimental.Trace('train_%02d' % i, step_num=i, _r=1):\n",
    "         inputs,labels = next(trainds)\n",
    "      \n",
    "      # print('batch_number = %s input shape = %s    labels shape = %s' %(i,inputs.shape,labels.shape))\n",
    "      # print('batch_number = %s labels = %s' %(i,labels))\n",
    "   # measure performance in images per second\n",
    "   duration = time.time() - start\n",
    "   if hvd.rank() == 0:\n",
    "      tf.profiler.experimental.stop()\n",
    "   images = config['data']['batch_size'] * args.nsteps\n",
    "   if hvd.rank() == 0:\n",
    "      print('imgs/sec = %5.2f' % ((images/duration)*hvd.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86512e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda/2022-07-01",
   "language": "python",
   "name": "conda-2022-07-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
